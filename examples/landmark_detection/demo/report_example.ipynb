{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report for models \n",
    "\n",
    "#### Import the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_alignment import FaceAlignment, LandmarksType\n",
    "\n",
    "from giskard_vision.landmark_detection.dataloaders.loaders import DataLoader300W\n",
    "from giskard_vision.landmark_detection.dataloaders.wrappers import (\n",
    "    CroppedDataLoader,\n",
    "    ResizedDataLoader,\n",
    "    HeadPoseDataLoader,\n",
    "    EthnicityDataLoader,\n",
    ")\n",
    "from giskard_vision.core.dataloaders.wrappers import (\n",
    "    CachedDataLoader,\n",
    "    FilteredDataLoader,\n",
    "    ColoredDataLoader,\n",
    "    BlurredDataLoader,\n",
    ")\n",
    "\n",
    "from giskard_vision.landmark_detection.models.wrappers import OpenCVWrapper, FaceAlignmentWrapper\n",
    "from giskard_vision.landmark_detection.tests.performance import NMEMean\n",
    "from giskard_vision.landmark_detection.marks.facial_parts import FacialParts\n",
    "from giskard_vision.landmark_detection.tests.report import Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_ref = DataLoader300W(dir_path=\"../datasets/300W/sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define your criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 12:01:44.698306: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# cropping\n",
    "dl_cropped_left = CroppedDataLoader(dl_ref, part=FacialParts.LEFT_HALF.value)\n",
    "dl_cropped_upper = CroppedDataLoader(dl_ref, part=FacialParts.UPPER_HALF.value)\n",
    "\n",
    "# resizing\n",
    "dl_resized = ResizedDataLoader(dl_ref, scales=0.5)\n",
    "\n",
    "# coloring\n",
    "dl_colored = ColoredDataLoader(dl_ref)\n",
    "\n",
    "# blurring\n",
    "dl_blurred = BlurredDataLoader(dl_ref)\n",
    "\n",
    "\n",
    "# head pose filtering\n",
    "def positive_roll(elt):\n",
    "    return elt[2][\"headPose\"][\"roll\"] > 0\n",
    "\n",
    "\n",
    "def negative_roll(elt):\n",
    "    return elt[2][\"headPose\"][\"roll\"] < 0\n",
    "\n",
    "\n",
    "cached_dl = CachedDataLoader(HeadPoseDataLoader(dl_ref), cache_size=None, cache_img=False, cache_marks=False)\n",
    "dl_positive_roll = FilteredDataLoader(cached_dl, positive_roll)\n",
    "dl_negative_roll = FilteredDataLoader(cached_dl, negative_roll)\n",
    "\n",
    "\n",
    "# ethnicity filtering\n",
    "def white_ethnicity(elt):\n",
    "    return elt[2][\"ethnicity\"] == \"white\"\n",
    "\n",
    "\n",
    "def latino_ethnicity(elt):\n",
    "    return elt[2][\"ethnicity\"] == \"latino hispanic\"\n",
    "\n",
    "\n",
    "cached_dl = CachedDataLoader(\n",
    "    EthnicityDataLoader(dl_ref, ethnicity_map={\"indian\": \"asian\"}), cache_size=None, cache_img=False, cache_marks=False\n",
    ")\n",
    "dl_white = FilteredDataLoader(cached_dl, white_ethnicity)\n",
    "dl_latino = FilteredDataLoader(cached_dl, latino_ethnicity)\n",
    "\n",
    "dataloaders_list = [\n",
    "    dl_cropped_left,\n",
    "    dl_cropped_upper,\n",
    "    dl_resized,\n",
    "    dl_colored,\n",
    "    dl_blurred,\n",
    "    dl_positive_roll,\n",
    "    dl_negative_roll,\n",
    "    dl_white,\n",
    "    dl_latino,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise the models you'd like to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from : lbfmodel.yaml\n"
     ]
    }
   ],
   "source": [
    "models_list = [\n",
    "    FaceAlignmentWrapper(model=FaceAlignment(LandmarksType.TWO_D, device=\"cpu\", flip_input=False)),\n",
    "    OpenCVWrapper(),\n",
    "]\n",
    "\n",
    "models_list = [models_list[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCVWrapper: Face not detected in processed image of batch 1 and index 0.\n",
      "OpenCVWrapper: Face not detected in processed image of batch 5 and index 0.\n",
      "OpenCVWrapper: Face not detected in processed image of batch 1 and index 0.\n",
      "OpenCVWrapper: Face not detected in processed image of batch 2 and index 0.\n",
      "OpenCVWrapper: Face not detected in processed image of batch 3 and index 0.\n",
      "OpenCVWrapper: Face not detected in processed image of batch 5 and index 0.\n"
     ]
    }
   ],
   "source": [
    "report = Report(models_list, dataloaders_list, dataloader_ref=dl_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the report into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>facial_part</th>\n",
       "      <th>dataloader</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>prediction_fail_rate</th>\n",
       "      <th>test</th>\n",
       "      <th>metric</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>threshold</th>\n",
       "      <th>passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>left half</td>\n",
       "      <td>300W cropped on left half</td>\n",
       "      <td>0.929891</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>-0.644057</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>upper half</td>\n",
       "      <td>300W cropped on upper half</td>\n",
       "      <td>0.943296</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>0.040216</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>entire face</td>\n",
       "      <td>300W resizing with ratios: 0.5</td>\n",
       "      <td>0.995143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>-0.079876</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>entire face</td>\n",
       "      <td>300W altered with color mode 7</td>\n",
       "      <td>1.316452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>entire face</td>\n",
       "      <td>300W blurred</td>\n",
       "      <td>1.483105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>-0.103017</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>entire face</td>\n",
       "      <td>(Cached (300W) with head-pose) filtered using ...</td>\n",
       "      <td>0.974038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>0.077927</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>entire face</td>\n",
       "      <td>(Cached (300W) with head-pose) filtered using ...</td>\n",
       "      <td>2.076661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>-0.019482</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>entire face</td>\n",
       "      <td>(Cached (300W) with ethnicity) filtered using ...</td>\n",
       "      <td>2.389328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>0.168421</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>entire face</td>\n",
       "      <td>(Cached (300W) with ethnicity) filtered using ...</td>\n",
       "      <td>1.945159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>-0.784538</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  facial_part                                         dataloader  \\\n",
       "0  OpenCV    left half                          300W cropped on left half   \n",
       "1  OpenCV   upper half                         300W cropped on upper half   \n",
       "2  OpenCV  entire face                     300W resizing with ratios: 0.5   \n",
       "3  OpenCV  entire face                     300W altered with color mode 7   \n",
       "4  OpenCV  entire face                                       300W blurred   \n",
       "5  OpenCV  entire face  (Cached (300W) with head-pose) filtered using ...   \n",
       "6  OpenCV  entire face  (Cached (300W) with head-pose) filtered using ...   \n",
       "7  OpenCV  entire face  (Cached (300W) with ethnicity) filtered using ...   \n",
       "8  OpenCV  entire face  (Cached (300W) with ethnicity) filtered using ...   \n",
       "\n",
       "   prediction_time  prediction_fail_rate      test    metric  metric_value  \\\n",
       "0         0.929891              0.564706  TestDiff  NME_mean     -0.644057   \n",
       "1         0.943296              0.682353  TestDiff  NME_mean      0.040216   \n",
       "2         0.995143              0.000000  TestDiff  NME_mean     -0.079876   \n",
       "3         1.316452              0.000000  TestDiff  NME_mean      0.001347   \n",
       "4         1.483105              0.000000  TestDiff  NME_mean     -0.103017   \n",
       "5         0.974038              0.000000  TestDiff  NME_mean      0.077927   \n",
       "6         2.076661              0.000000  TestDiff  NME_mean     -0.019482   \n",
       "7         2.389328              0.000000  TestDiff  NME_mean      0.168421   \n",
       "8         1.945159              0.000000  TestDiff  NME_mean     -0.784538   \n",
       "\n",
       "   threshold  passed  \n",
       "0       -0.1    True  \n",
       "1       -0.1   False  \n",
       "2       -0.1   False  \n",
       "3       -0.1   False  \n",
       "4       -0.1    True  \n",
       "5       -0.1   False  \n",
       "6       -0.1   False  \n",
       "7       -0.1   False  \n",
       "8       -0.1    True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Report\n",
    "Here's a full prepared report to compare `FaceAlignment` and `OpenCV` models on the full `300W-indoor` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>facial_part</th>\n",
       "      <th>dataloader</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>prediction_fail_rate</th>\n",
       "      <th>test</th>\n",
       "      <th>metric</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>threshold</th>\n",
       "      <th>passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FaceAlignment</td>\n",
       "      <td>left half</td>\n",
       "      <td>300W cropped on left half</td>\n",
       "      <td>97.645192</td>\n",
       "      <td>0.968260</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>-0.627014</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FaceAlignment</td>\n",
       "      <td>upper half</td>\n",
       "      <td>300W cropped on upper half</td>\n",
       "      <td>77.467558</td>\n",
       "      <td>0.971765</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>-0.587295</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FaceAlignment</td>\n",
       "      <td>entire face</td>\n",
       "      <td>300W resizing with ratios: 0.5</td>\n",
       "      <td>123.234188</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>0.691124</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FaceAlignment</td>\n",
       "      <td>entire face</td>\n",
       "      <td>300W altered with color mode 7</td>\n",
       "      <td>77.377963</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>0.152823</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FaceAlignment</td>\n",
       "      <td>entire face</td>\n",
       "      <td>300W blurred</td>\n",
       "      <td>78.804337</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>0.448503</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FaceAlignment</td>\n",
       "      <td>entire face</td>\n",
       "      <td>(Cached (300W) with head-pose) filtered using ...</td>\n",
       "      <td>67.365618</td>\n",
       "      <td>0.949444</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>-0.611439</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FaceAlignment</td>\n",
       "      <td>entire face</td>\n",
       "      <td>(Cached (300W) with head-pose) filtered using ...</td>\n",
       "      <td>49.014326</td>\n",
       "      <td>0.934167</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>1.990828</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FaceAlignment</td>\n",
       "      <td>entire face</td>\n",
       "      <td>(Cached (300W) with ethnicity) filtered using ...</td>\n",
       "      <td>52.884618</td>\n",
       "      <td>0.950238</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>-0.695888</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FaceAlignment</td>\n",
       "      <td>entire face</td>\n",
       "      <td>(Cached (300W) with ethnicity) filtered using ...</td>\n",
       "      <td>40.927982</td>\n",
       "      <td>0.892719</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>3.921029</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>left half</td>\n",
       "      <td>300W cropped on left half</td>\n",
       "      <td>318.501807</td>\n",
       "      <td>0.659020</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>-0.944248</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>upper half</td>\n",
       "      <td>300W cropped on upper half</td>\n",
       "      <td>315.719642</td>\n",
       "      <td>0.738824</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>-0.947725</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>entire face</td>\n",
       "      <td>300W resizing with ratios: 0.5</td>\n",
       "      <td>350.587494</td>\n",
       "      <td>0.111667</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>-0.100617</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>entire face</td>\n",
       "      <td>300W altered with color mode 7</td>\n",
       "      <td>500.571767</td>\n",
       "      <td>0.101667</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>-0.013678</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>entire face</td>\n",
       "      <td>300W blurred</td>\n",
       "      <td>467.860867</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>-0.124634</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>entire face</td>\n",
       "      <td>(Cached (300W) with head-pose) filtered using ...</td>\n",
       "      <td>445.922342</td>\n",
       "      <td>0.106111</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>0.240608</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>entire face</td>\n",
       "      <td>(Cached (300W) with head-pose) filtered using ...</td>\n",
       "      <td>299.804139</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>-0.416896</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>entire face</td>\n",
       "      <td>(Cached (300W) with ethnicity) filtered using ...</td>\n",
       "      <td>342.713824</td>\n",
       "      <td>0.071190</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>-0.046276</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>OpenCV</td>\n",
       "      <td>entire face</td>\n",
       "      <td>(Cached (300W) with ethnicity) filtered using ...</td>\n",
       "      <td>268.403679</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>TestDiff</td>\n",
       "      <td>NME_mean</td>\n",
       "      <td>-0.450501</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  facial_part  \\\n",
       "0   FaceAlignment    left half   \n",
       "1   FaceAlignment   upper half   \n",
       "2   FaceAlignment  entire face   \n",
       "3   FaceAlignment  entire face   \n",
       "4   FaceAlignment  entire face   \n",
       "5   FaceAlignment  entire face   \n",
       "6   FaceAlignment  entire face   \n",
       "7   FaceAlignment  entire face   \n",
       "8   FaceAlignment  entire face   \n",
       "9          OpenCV    left half   \n",
       "10         OpenCV   upper half   \n",
       "11         OpenCV  entire face   \n",
       "12         OpenCV  entire face   \n",
       "13         OpenCV  entire face   \n",
       "14         OpenCV  entire face   \n",
       "15         OpenCV  entire face   \n",
       "16         OpenCV  entire face   \n",
       "17         OpenCV  entire face   \n",
       "\n",
       "                                           dataloader  prediction_time  \\\n",
       "0                           300W cropped on left half        97.645192   \n",
       "1                          300W cropped on upper half        77.467558   \n",
       "2                      300W resizing with ratios: 0.5       123.234188   \n",
       "3                      300W altered with color mode 7        77.377963   \n",
       "4                                        300W blurred        78.804337   \n",
       "5   (Cached (300W) with head-pose) filtered using ...        67.365618   \n",
       "6   (Cached (300W) with head-pose) filtered using ...        49.014326   \n",
       "7   (Cached (300W) with ethnicity) filtered using ...        52.884618   \n",
       "8   (Cached (300W) with ethnicity) filtered using ...        40.927982   \n",
       "9                           300W cropped on left half       318.501807   \n",
       "10                         300W cropped on upper half       315.719642   \n",
       "11                     300W resizing with ratios: 0.5       350.587494   \n",
       "12                     300W altered with color mode 7       500.571767   \n",
       "13                                       300W blurred       467.860867   \n",
       "14  (Cached (300W) with head-pose) filtered using ...       445.922342   \n",
       "15  (Cached (300W) with head-pose) filtered using ...       299.804139   \n",
       "16  (Cached (300W) with ethnicity) filtered using ...       342.713824   \n",
       "17  (Cached (300W) with ethnicity) filtered using ...       268.403679   \n",
       "\n",
       "    prediction_fail_rate      test    metric  metric_value  threshold  passed  \n",
       "0               0.968260  TestDiff  NME_mean     -0.627014       -0.1    True  \n",
       "1               0.971765  TestDiff  NME_mean     -0.587295       -0.1    True  \n",
       "2               0.733333  TestDiff  NME_mean      0.691124       -0.1   False  \n",
       "3               0.943333  TestDiff  NME_mean      0.152823       -0.1   False  \n",
       "4               0.943333  TestDiff  NME_mean      0.448503       -0.1   False  \n",
       "5               0.949444  TestDiff  NME_mean     -0.611439       -0.1    True  \n",
       "6               0.934167  TestDiff  NME_mean      1.990828       -0.1   False  \n",
       "7               0.950238  TestDiff  NME_mean     -0.695888       -0.1    True  \n",
       "8               0.892719  TestDiff  NME_mean      3.921029       -0.1   False  \n",
       "9               0.659020  TestDiff  NME_mean     -0.944248       -0.1    True  \n",
       "10              0.738824  TestDiff  NME_mean     -0.947725       -0.1    True  \n",
       "11              0.111667  TestDiff  NME_mean     -0.100617       -0.1    True  \n",
       "12              0.101667  TestDiff  NME_mean     -0.013678       -0.1   False  \n",
       "13              0.091667  TestDiff  NME_mean     -0.124634       -0.1    True  \n",
       "14              0.106111  TestDiff  NME_mean      0.240608       -0.1   False  \n",
       "15              0.107500  TestDiff  NME_mean     -0.416896       -0.1    True  \n",
       "16              0.071190  TestDiff  NME_mean     -0.046276       -0.1   False  \n",
       "17              0.053333  TestDiff  NME_mean     -0.450501       -0.1    True  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "full_report = pd.read_csv(\"full_report.csv\")\n",
    "full_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
